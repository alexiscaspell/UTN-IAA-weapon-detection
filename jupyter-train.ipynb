{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31f3505-ae92-4973-a868-8cc8525942e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-09 09:31:12.945035: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2021-10-09 09:31:12.945066: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D,Conv2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import  img_to_array\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Image manipulations and arranging data\n",
    "import os\n",
    "from PIL import Image\n",
    "# import theano\n",
    "# theano.config.optimizer=\"None\"\n",
    "#Sklearn to modify the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8441e062-aa81-46fb-96e1-97fc7e935c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = 240,240\n",
    "\n",
    "PATH_SEP=\"/\"\n",
    "\n",
    "path1='test'\n",
    "path2='train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d48a40f-47a5-4fad-8b82-cf5a1bf97021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tarjeta\n",
      "pistol\n",
      "billete\n",
      "knife\n",
      "monedero\n",
      "smartphone\n"
     ]
    }
   ],
   "source": [
    "classes=os.listdir(path2)\n",
    "x=[]\n",
    "y=[]\n",
    "count = 0\n",
    "for fol in classes:\n",
    "    print (fol)\n",
    "    imgfiles=os.listdir(path2 + PATH_SEP + fol)\n",
    "    for img in imgfiles:\n",
    "        try:\n",
    "            im=Image.open(path2+PATH_SEP+fol+PATH_SEP+img)\n",
    "            im=im.convert(mode='RGB')\n",
    "            imrs=im.resize((m,n))\n",
    "            imrs=img_to_array(imrs)/255\n",
    "            imrs=imrs.transpose(2,0,1)\n",
    "            imrs=imrs.reshape(3,m,n)\n",
    "            x.append(imrs)\n",
    "            y.append(count)\n",
    "        except:\n",
    "            pass\n",
    "    count += 1\n",
    "\n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7ffbcc-665f-4754-9f78-649a7797d05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.06666667, 0.06666667, 0.06666667, ..., 0.29411766,\n",
       "          0.28627452, 0.2784314 ],\n",
       "         [0.06666667, 0.07450981, 0.07058824, ..., 0.2901961 ,\n",
       "          0.2784314 , 0.27450982],\n",
       "         [0.07058824, 0.07058824, 0.08235294, ..., 0.28627452,\n",
       "          0.28235295, 0.27058825],\n",
       "         ...,\n",
       "         [0.07450981, 0.08235294, 0.09019608, ..., 0.90588236,\n",
       "          0.8901961 , 0.8745098 ],\n",
       "         [0.07058824, 0.07843138, 0.07843138, ..., 0.9137255 ,\n",
       "          0.90588236, 0.89411765],\n",
       "         [0.07058824, 0.07058824, 0.08235294, ..., 0.91764706,\n",
       "          0.9098039 , 0.90588236]],\n",
       "\n",
       "        [[0.2509804 , 0.2509804 , 0.2509804 , ..., 0.2509804 ,\n",
       "          0.24313726, 0.23921569],\n",
       "         [0.24705882, 0.24705882, 0.24313726, ..., 0.2509804 ,\n",
       "          0.24705882, 0.24313726],\n",
       "         [0.25490198, 0.24705882, 0.24705882, ..., 0.25490198,\n",
       "          0.24313726, 0.23921569],\n",
       "         ...,\n",
       "         [0.33333334, 0.32941177, 0.3372549 , ..., 0.89411765,\n",
       "          0.88235295, 0.8627451 ],\n",
       "         [0.32941177, 0.32941177, 0.33333334, ..., 0.9019608 ,\n",
       "          0.8980392 , 0.8784314 ],\n",
       "         [0.3254902 , 0.3254902 , 0.33333334, ..., 0.90588236,\n",
       "          0.9019608 , 0.89411765]],\n",
       "\n",
       "        [[0.37254903, 0.3764706 , 0.37254903, ..., 0.21568628,\n",
       "          0.20392157, 0.20392157],\n",
       "         [0.37254903, 0.3764706 , 0.37254903, ..., 0.21176471,\n",
       "          0.20392157, 0.19607843],\n",
       "         [0.3647059 , 0.3647059 , 0.36862746, ..., 0.21176471,\n",
       "          0.20392157, 0.19215687],\n",
       "         ...,\n",
       "         [0.45882353, 0.46666667, 0.46666667, ..., 0.85490197,\n",
       "          0.8392157 , 0.8235294 ],\n",
       "         [0.4627451 , 0.4627451 , 0.45882353, ..., 0.8666667 ,\n",
       "          0.8509804 , 0.84313726],\n",
       "         [0.45490196, 0.45882353, 0.4627451 , ..., 0.87058824,\n",
       "          0.85882354, 0.85490197]]],\n",
       "\n",
       "\n",
       "       [[[0.42352942, 0.42745098, 0.42745098, ..., 0.6901961 ,\n",
       "          0.6901961 , 0.6901961 ],\n",
       "         [0.43137255, 0.42352942, 0.42352942, ..., 0.6901961 ,\n",
       "          0.6901961 , 0.6901961 ],\n",
       "         [0.42745098, 0.42745098, 0.41960785, ..., 0.69411767,\n",
       "          0.69411767, 0.69411767],\n",
       "         ...,\n",
       "         [0.12941177, 0.12941177, 0.11372549, ..., 0.20784314,\n",
       "          0.2       , 0.20784314],\n",
       "         [0.10196079, 0.12156863, 0.12156863, ..., 0.21960784,\n",
       "          0.21568628, 0.20784314],\n",
       "         [0.11372549, 0.12156863, 0.12156863, ..., 0.2       ,\n",
       "          0.2       , 0.18039216]],\n",
       "\n",
       "        [[0.25490198, 0.25490198, 0.2509804 , ..., 0.6745098 ,\n",
       "          0.67058825, 0.67058825],\n",
       "         [0.2627451 , 0.25490198, 0.2509804 , ..., 0.6745098 ,\n",
       "          0.6745098 , 0.6745098 ],\n",
       "         [0.2627451 , 0.25882354, 0.25490198, ..., 0.6784314 ,\n",
       "          0.6745098 , 0.6745098 ],\n",
       "         ...,\n",
       "         [0.13333334, 0.12941177, 0.10588235, ..., 0.19607843,\n",
       "          0.1882353 , 0.19215687],\n",
       "         [0.09411765, 0.11764706, 0.11372549, ..., 0.20784314,\n",
       "          0.20784314, 0.19215687],\n",
       "         [0.10588235, 0.11372549, 0.11372549, ..., 0.1882353 ,\n",
       "          0.19215687, 0.17254902]],\n",
       "\n",
       "        [[0.16862746, 0.16862746, 0.16470589, ..., 0.654902  ,\n",
       "          0.65882355, 0.65882355],\n",
       "         [0.17254902, 0.16470589, 0.16862746, ..., 0.65882355,\n",
       "          0.65882355, 0.654902  ],\n",
       "         [0.1882353 , 0.18039216, 0.1764706 , ..., 0.65882355,\n",
       "          0.65882355, 0.6627451 ],\n",
       "         ...,\n",
       "         [0.15686275, 0.14901961, 0.13333334, ..., 0.21176471,\n",
       "          0.20784314, 0.20392157],\n",
       "         [0.11372549, 0.14117648, 0.14117648, ..., 0.22352941,\n",
       "          0.21176471, 0.20392157],\n",
       "         [0.12941177, 0.14117648, 0.14117648, ..., 0.2       ,\n",
       "          0.20784314, 0.18431373]]],\n",
       "\n",
       "\n",
       "       [[[0.09019608, 0.27450982, 0.43529412, ..., 0.34901962,\n",
       "          0.34509805, 0.34509805],\n",
       "         [0.09019608, 0.2627451 , 0.43529412, ..., 0.3529412 ,\n",
       "          0.3529412 , 0.36078432],\n",
       "         [0.08627451, 0.25490198, 0.4392157 , ..., 0.3529412 ,\n",
       "          0.34117648, 0.3529412 ],\n",
       "         ...,\n",
       "         [0.00784314, 0.00784314, 0.01568628, ..., 0.04705882,\n",
       "          0.04705882, 0.05098039],\n",
       "         [0.01176471, 0.01568628, 0.01960784, ..., 0.05098039,\n",
       "          0.04705882, 0.04705882],\n",
       "         [0.01568628, 0.02352941, 0.03137255, ..., 0.04705882,\n",
       "          0.04705882, 0.04313726]],\n",
       "\n",
       "        [[0.10196079, 0.25490198, 0.38039216, ..., 0.01960784,\n",
       "          0.02745098, 0.02352941],\n",
       "         [0.10588235, 0.24313726, 0.38039216, ..., 0.01960784,\n",
       "          0.02745098, 0.02745098],\n",
       "         [0.09803922, 0.23921569, 0.38039216, ..., 0.02352941,\n",
       "          0.01960784, 0.03137255],\n",
       "         ...,\n",
       "         [0.00784314, 0.00784314, 0.01568628, ..., 0.05882353,\n",
       "          0.05882353, 0.0627451 ],\n",
       "         [0.01176471, 0.01568628, 0.02352941, ..., 0.0627451 ,\n",
       "          0.05882353, 0.05882353],\n",
       "         [0.01960784, 0.02745098, 0.03529412, ..., 0.05882353,\n",
       "          0.05882353, 0.05490196]],\n",
       "\n",
       "        [[0.12156863, 0.26666668, 0.3137255 , ..., 0.08235294,\n",
       "          0.08235294, 0.07843138],\n",
       "         [0.12156863, 0.25882354, 0.3137255 , ..., 0.08235294,\n",
       "          0.08235294, 0.08627451],\n",
       "         [0.11764706, 0.2509804 , 0.3137255 , ..., 0.08627451,\n",
       "          0.07843138, 0.09019608],\n",
       "         ...,\n",
       "         [0.01568628, 0.01568628, 0.02352941, ..., 0.07450981,\n",
       "          0.07843138, 0.08235294],\n",
       "         [0.01960784, 0.02352941, 0.03137255, ..., 0.07843138,\n",
       "          0.07843138, 0.07843138],\n",
       "         [0.02745098, 0.03529412, 0.04313726, ..., 0.07843138,\n",
       "          0.07843138, 0.07450981]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.3647059 , 0.3647059 , 0.3647059 , ..., 0.26666668,\n",
       "          0.27058825, 0.26666668],\n",
       "         [0.3647059 , 0.36862746, 0.36862746, ..., 0.26666668,\n",
       "          0.27058825, 0.26666668],\n",
       "         [0.36862746, 0.37254903, 0.36862746, ..., 0.27058825,\n",
       "          0.26666668, 0.26666668],\n",
       "         ...,\n",
       "         [0.4117647 , 0.41960785, 0.42352942, ..., 0.25882354,\n",
       "          0.26666668, 0.26666668],\n",
       "         [0.42352942, 0.42745098, 0.42745098, ..., 0.25882354,\n",
       "          0.2627451 , 0.2627451 ],\n",
       "         [0.42745098, 0.43137255, 0.4392157 , ..., 0.25882354,\n",
       "          0.2627451 , 0.2627451 ]],\n",
       "\n",
       "        [[0.34901962, 0.34901962, 0.34901962, ..., 0.27450982,\n",
       "          0.27058825, 0.26666668],\n",
       "         [0.34901962, 0.3529412 , 0.3529412 , ..., 0.27450982,\n",
       "          0.27058825, 0.26666668],\n",
       "         [0.3529412 , 0.35686275, 0.3529412 , ..., 0.27450982,\n",
       "          0.26666668, 0.26666668],\n",
       "         ...,\n",
       "         [0.3137255 , 0.31764707, 0.31764707, ..., 0.2627451 ,\n",
       "          0.26666668, 0.26666668],\n",
       "         [0.32156864, 0.3254902 , 0.32156864, ..., 0.2627451 ,\n",
       "          0.26666668, 0.2627451 ],\n",
       "         [0.33333334, 0.3372549 , 0.33333334, ..., 0.2627451 ,\n",
       "          0.26666668, 0.26666668]],\n",
       "\n",
       "        [[0.3372549 , 0.3372549 , 0.3372549 , ..., 0.27058825,\n",
       "          0.27058825, 0.26666668],\n",
       "         [0.3372549 , 0.34117648, 0.34117648, ..., 0.27058825,\n",
       "          0.27058825, 0.27058825],\n",
       "         [0.34117648, 0.34509805, 0.34117648, ..., 0.27450982,\n",
       "          0.27450982, 0.27450982],\n",
       "         ...,\n",
       "         [0.23137255, 0.23529412, 0.23921569, ..., 0.27058825,\n",
       "          0.27450982, 0.27450982],\n",
       "         [0.23529412, 0.23529412, 0.24313726, ..., 0.27058825,\n",
       "          0.27450982, 0.27058825],\n",
       "         [0.24313726, 0.24313726, 0.25490198, ..., 0.27058825,\n",
       "          0.27450982, 0.27450982]]],\n",
       "\n",
       "\n",
       "       [[[0.3764706 , 0.38039216, 0.39215687, ..., 0.7372549 ,\n",
       "          0.74509805, 0.74509805],\n",
       "         [0.3764706 , 0.38431373, 0.3882353 , ..., 0.74509805,\n",
       "          0.74509805, 0.74509805],\n",
       "         [0.38039216, 0.38039216, 0.38431373, ..., 0.7490196 ,\n",
       "          0.74509805, 0.7490196 ],\n",
       "         ...,\n",
       "         [0.07450981, 0.07058824, 0.0627451 , ..., 0.47843137,\n",
       "          0.4745098 , 0.47058824],\n",
       "         [0.09019608, 0.08627451, 0.08235294, ..., 0.47058824,\n",
       "          0.46666667, 0.4627451 ],\n",
       "         [0.07843138, 0.07843138, 0.07843138, ..., 0.46666667,\n",
       "          0.4627451 , 0.45490196]],\n",
       "\n",
       "        [[0.2509804 , 0.2509804 , 0.25490198, ..., 0.72156864,\n",
       "          0.7176471 , 0.7176471 ],\n",
       "         [0.2509804 , 0.25490198, 0.25490198, ..., 0.72156864,\n",
       "          0.72156864, 0.72156864],\n",
       "         [0.25490198, 0.2509804 , 0.25490198, ..., 0.7254902 ,\n",
       "          0.7254902 , 0.7254902 ],\n",
       "         ...,\n",
       "         [0.07058824, 0.07058824, 0.05882353, ..., 0.46666667,\n",
       "          0.45882353, 0.45882353],\n",
       "         [0.08235294, 0.08627451, 0.08627451, ..., 0.45490196,\n",
       "          0.45490196, 0.45490196],\n",
       "         [0.07843138, 0.08235294, 0.08627451, ..., 0.4509804 ,\n",
       "          0.44705883, 0.44705883]],\n",
       "\n",
       "        [[0.08627451, 0.08235294, 0.07450981, ..., 0.69803923,\n",
       "          0.7019608 , 0.7058824 ],\n",
       "         [0.08235294, 0.07843138, 0.07843138, ..., 0.7019608 ,\n",
       "          0.7019608 , 0.7019608 ],\n",
       "         [0.07450981, 0.07058824, 0.07450981, ..., 0.7058824 ,\n",
       "          0.7058824 , 0.7058824 ],\n",
       "         ...,\n",
       "         [0.09019608, 0.08627451, 0.07450981, ..., 0.4627451 ,\n",
       "          0.4509804 , 0.45882353],\n",
       "         [0.10588235, 0.10196079, 0.10196079, ..., 0.4509804 ,\n",
       "          0.44313726, 0.4509804 ],\n",
       "         [0.09803922, 0.10196079, 0.10588235, ..., 0.44313726,\n",
       "          0.44313726, 0.44705883]]],\n",
       "\n",
       "\n",
       "       [[[0.34901962, 0.3647059 , 0.3647059 , ..., 0.7411765 ,\n",
       "          0.7372549 , 0.7372549 ],\n",
       "         [0.36078432, 0.36078432, 0.3647059 , ..., 0.74509805,\n",
       "          0.7411765 , 0.74509805],\n",
       "         [0.36078432, 0.3529412 , 0.36078432, ..., 0.7490196 ,\n",
       "          0.74509805, 0.7490196 ],\n",
       "         ...,\n",
       "         [0.0627451 , 0.07058824, 0.07058824, ..., 0.47843137,\n",
       "          0.4745098 , 0.46666667],\n",
       "         [0.06666667, 0.07058824, 0.07450981, ..., 0.47058824,\n",
       "          0.46666667, 0.45882353],\n",
       "         [0.07058824, 0.07450981, 0.07058824, ..., 0.4627451 ,\n",
       "          0.45882353, 0.4509804 ]],\n",
       "\n",
       "        [[0.23529412, 0.22745098, 0.23137255, ..., 0.7137255 ,\n",
       "          0.7137255 , 0.7137255 ],\n",
       "         [0.23137255, 0.22745098, 0.23137255, ..., 0.7176471 ,\n",
       "          0.7176471 , 0.7137255 ],\n",
       "         [0.23529412, 0.23137255, 0.23137255, ..., 0.7176471 ,\n",
       "          0.7176471 , 0.7176471 ],\n",
       "         ...,\n",
       "         [0.05098039, 0.0627451 , 0.06666667, ..., 0.45490196,\n",
       "          0.45490196, 0.4509804 ],\n",
       "         [0.05098039, 0.05882353, 0.0627451 , ..., 0.44705883,\n",
       "          0.44313726, 0.44313726],\n",
       "         [0.0627451 , 0.06666667, 0.0627451 , ..., 0.44313726,\n",
       "          0.4392157 , 0.43529412]],\n",
       "\n",
       "        [[0.04705882, 0.05098039, 0.04705882, ..., 0.6745098 ,\n",
       "          0.6784314 , 0.6784314 ],\n",
       "         [0.04705882, 0.04705882, 0.04705882, ..., 0.6745098 ,\n",
       "          0.68235296, 0.68235296],\n",
       "         [0.04313726, 0.04313726, 0.04705882, ..., 0.68235296,\n",
       "          0.6862745 , 0.68235296],\n",
       "         ...,\n",
       "         [0.07450981, 0.08627451, 0.08235294, ..., 0.44313726,\n",
       "          0.44313726, 0.44313726],\n",
       "         [0.07058824, 0.08627451, 0.08235294, ..., 0.4392157 ,\n",
       "          0.43529412, 0.43529412],\n",
       "         [0.08235294, 0.08627451, 0.08627451, ..., 0.43137255,\n",
       "          0.42745098, 0.42745098]]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e471a4af-44c8-49c5-8778-e2055d4dce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "nb_classes=len(classes)\n",
    "nb_epoch=20\n",
    "nb_filters=128\n",
    "nb_pool=2\n",
    "nb_conv=3\n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(x,y,test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3875f39d-5a9b-4973-944d-cc9d7e5fe38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques, id_train=np.unique(y_train,return_inverse=True)\n",
    "Y_train=np_utils.to_categorical(id_train,nb_classes)\n",
    "uniques, id_test=np.unique(y_test,return_inverse=True)\n",
    "Y_test=np_utils.to_categorical(id_test,nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67350c38-3320-45ab-b9d9-11c441e2d643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-09 09:31:31.184664: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-10-09 09:31:31.184704: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-10-09 09:31:31.184736: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ff2f601ab2a7): /proc/driver/nvidia/version does not exist\n",
      "2021-10-09 09:31:31.185008: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-09 09:31:31.210356: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2099940000 Hz\n",
      "2021-10-09 09:31:31.211193: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b17fa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-10-09 09:31:31.211239: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Convolution2D(nb_filters,nb_conv,nb_conv,padding='same',input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(int(nb_filters/2),nb_conv,nb_conv,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(nb_pool,nb_pool)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution2D(int(nb_filters/4),nb_conv,nb_conv,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(int(nb_filters/8),nb_conv,nb_conv,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool,nb_pool), padding='same'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e84253bc-03ad-45a3-aaf1-e695698db767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-09 09:31:31.325108: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 341452800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.7533 - accuracy: 0.4393 - val_loss: 1.7086 - val_accuracy: 0.5403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-09 09:31:32.371254: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 85708800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/60\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 1.6720 - accuracy: 0.5506 - val_loss: 1.6363 - val_accuracy: 0.5403\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 1.6057 - accuracy: 0.5506 - val_loss: 1.5731 - val_accuracy: 0.5403\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 1.5460 - accuracy: 0.5506 - val_loss: 1.5190 - val_accuracy: 0.5403\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 1.4978 - accuracy: 0.5506 - val_loss: 1.4757 - val_accuracy: 0.5403\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 1.4556 - accuracy: 0.5506 - val_loss: 1.4358 - val_accuracy: 0.5403\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 1.4257 - accuracy: 0.5506 - val_loss: 1.4119 - val_accuracy: 0.5403\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 1.4103 - accuracy: 0.5506 - val_loss: 1.3938 - val_accuracy: 0.5403\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 1.3963 - accuracy: 0.5506 - val_loss: 1.3784 - val_accuracy: 0.5403\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 1.3838 - accuracy: 0.5506 - val_loss: 1.3655 - val_accuracy: 0.5403\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 1.3755 - accuracy: 0.5506 - val_loss: 1.3580 - val_accuracy: 0.5403\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.3682 - accuracy: 0.5506 - val_loss: 1.3483 - val_accuracy: 0.5403\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 1.3677 - accuracy: 0.5506 - val_loss: 1.3439 - val_accuracy: 0.5403\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 1.3577 - accuracy: 0.5506 - val_loss: 1.3365 - val_accuracy: 0.5403\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.3507 - accuracy: 0.5506 - val_loss: 1.3273 - val_accuracy: 0.5403\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.3393 - accuracy: 0.5506 - val_loss: 1.3206 - val_accuracy: 0.5403\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 1.3321 - accuracy: 0.5506 - val_loss: 1.3095 - val_accuracy: 0.5403\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.3238 - accuracy: 0.5506 - val_loss: 1.3016 - val_accuracy: 0.5403\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 1.3221 - accuracy: 0.5506 - val_loss: 1.2905 - val_accuracy: 0.5403\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 1.3075 - accuracy: 0.5506 - val_loss: 1.2805 - val_accuracy: 0.5403\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 1.3014 - accuracy: 0.5506 - val_loss: 1.2687 - val_accuracy: 0.5403\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 1.2937 - accuracy: 0.5486 - val_loss: 1.2595 - val_accuracy: 0.5403\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.2738 - accuracy: 0.5486 - val_loss: 1.2433 - val_accuracy: 0.5403\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 1.2557 - accuracy: 0.5547 - val_loss: 1.2310 - val_accuracy: 0.5403\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 1.2555 - accuracy: 0.5547 - val_loss: 1.2152 - val_accuracy: 0.5403\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 1.2368 - accuracy: 0.5587 - val_loss: 1.2124 - val_accuracy: 0.5403\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 1.2279 - accuracy: 0.5587 - val_loss: 1.1956 - val_accuracy: 0.5403\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.2243 - accuracy: 0.5668 - val_loss: 1.1791 - val_accuracy: 0.5403\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 1.2070 - accuracy: 0.5648 - val_loss: 1.1764 - val_accuracy: 0.5403\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.2077 - accuracy: 0.5729 - val_loss: 1.1894 - val_accuracy: 0.5403\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 1.1988 - accuracy: 0.5688 - val_loss: 1.1592 - val_accuracy: 0.5403\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.1983 - accuracy: 0.5547 - val_loss: 1.1984 - val_accuracy: 0.5403\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 1.1905 - accuracy: 0.5688 - val_loss: 1.1647 - val_accuracy: 0.5403\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 1.1810 - accuracy: 0.5688 - val_loss: 1.1531 - val_accuracy: 0.5726\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 1.1625 - accuracy: 0.5688 - val_loss: 1.1591 - val_accuracy: 0.6048\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 1.1676 - accuracy: 0.5810 - val_loss: 1.1254 - val_accuracy: 0.5726\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 1.1317 - accuracy: 0.5789 - val_loss: 1.1197 - val_accuracy: 0.5726\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 1.1357 - accuracy: 0.6032 - val_loss: 1.1124 - val_accuracy: 0.5645\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 1.1631 - accuracy: 0.5810 - val_loss: 1.1201 - val_accuracy: 0.5726\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 1.1274 - accuracy: 0.5931 - val_loss: 1.0966 - val_accuracy: 0.5887\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 1.1096 - accuracy: 0.6255 - val_loss: 1.0849 - val_accuracy: 0.5968\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.1097 - accuracy: 0.5891 - val_loss: 1.1064 - val_accuracy: 0.6532\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.0948 - accuracy: 0.5951 - val_loss: 1.0756 - val_accuracy: 0.6613\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 1.0833 - accuracy: 0.6174 - val_loss: 1.1142 - val_accuracy: 0.6452\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 1.0939 - accuracy: 0.6113 - val_loss: 1.0748 - val_accuracy: 0.6210\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 1.0778 - accuracy: 0.6174 - val_loss: 1.0495 - val_accuracy: 0.6774\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 1.0853 - accuracy: 0.6174 - val_loss: 1.0515 - val_accuracy: 0.6694\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 1.0655 - accuracy: 0.6093 - val_loss: 1.0617 - val_accuracy: 0.6532\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 1.0706 - accuracy: 0.6235 - val_loss: 1.0357 - val_accuracy: 0.6694\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 1.0940 - accuracy: 0.6073 - val_loss: 1.0661 - val_accuracy: 0.6129\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.0644 - accuracy: 0.6174 - val_loss: 1.0344 - val_accuracy: 0.6694\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 1.0492 - accuracy: 0.6437 - val_loss: 1.0702 - val_accuracy: 0.6452\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.0326 - accuracy: 0.6478 - val_loss: 1.0109 - val_accuracy: 0.6855\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 1.0436 - accuracy: 0.6215 - val_loss: 1.0297 - val_accuracy: 0.6774\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.0500 - accuracy: 0.6154 - val_loss: 1.0240 - val_accuracy: 0.6694\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 1.0204 - accuracy: 0.6498 - val_loss: 0.9910 - val_accuracy: 0.6774\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.0637 - accuracy: 0.6194 - val_loss: 1.0956 - val_accuracy: 0.6371\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.0324 - accuracy: 0.6478 - val_loss: 1.0074 - val_accuracy: 0.6613\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 1.0269 - accuracy: 0.6518 - val_loss: 1.0129 - val_accuracy: 0.6774\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 1.0172 - accuracy: 0.6417 - val_loss: 1.0277 - val_accuracy: 0.6613\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=60\n",
    "batch_size=32\n",
    "model.fit(x_train,Y_train,batch_size=batch_size,epochs=nb_epoch,verbose=1,validation_data=(x_test, Y_test))\n",
    "\n",
    "model.save(\"model_latest.h5\",overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88a9e92e-2c58-4a92-8cf6-1f84d9406125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ARCHIVO: celular18.jpg\n",
      "\n",
      "TARJETA:0.0907110646367073\n",
      "PISTOL:0.1810309886932373\n",
      "BILLETE:0.12921142578125\n",
      "KNIFE:0.3885958194732666\n",
      "MONEDERO:0.07103518396615982\n",
      "SMARTPHONE:0.13941559195518494\n",
      "\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 1, 80, 128)        276608    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1, 80, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 27, 64)         73792     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 27, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 27, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 9, 32)          18464     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 3, 16)          4624      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 1, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 774       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 378,486\n",
      "Trainable params: 378,486\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "files=os.listdir(path1)\n",
    "\n",
    "img=files[randint(0,len(files)-1)]\n",
    "\n",
    "print (f\"\\nARCHIVO: {img}\\n\")\n",
    "\n",
    "im = Image.open(path1 +PATH_SEP+ img)\n",
    "imrs = im.resize((m,n))\n",
    "imrs=img_to_array(imrs)/255\n",
    "imrs=imrs.transpose(2,0,1)\n",
    "imrs=imrs.reshape(3,m,n)\n",
    "\n",
    "x=[]\n",
    "x.append(imrs)\n",
    "x=np.array(x)\n",
    "predictions = model.predict(x)\n",
    "# print (predictions)\n",
    "\n",
    "for i,e in enumerate(list(predictions)[0]):\n",
    "    print(f\"{classes[i].upper()}:{e}\")\n",
    "    \n",
    "print (\"\\n\")\n",
    "print (model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
